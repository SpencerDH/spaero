---
title: "Getting Started with spaero"
author: "Eamon O'Dea"
date: "`r Sys.Date()`"
output: rmarkdown::pdf_document
bibliography: ews.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

The spaero package (pronounced sparrow) currently supports the
estimation of statistics along rolling windows of time series. Such
estimates may in some cases provide signals that the system generating
the data is approaching a critical transition. Examples of critical
transitions include the eutrophication of lakes, changes in climate,
and emergence or eradication of infectious diseases. The spearo
package will be further developed to further support statistical
methods to predict critical transititions in infectious disease
systems. Because these methods will be based on generic properties of
dynamical systems, they have the potential to apply to a broad range
of models. The spaero package will also be developed to support
computational experiments designed to evaluate these methods. This
document provides a rudimentary demonstration of such methods on
simulated data.

We will sample a time series from a linear noise approximation to an
SIS (Susceptible--Infected--Susceptible) epidemic model. See
@keeling2008 for an introduction to this model. The linear noise
approximation is highly accurate for a large population, is easy to
simulate from, and leads to simple expected values of the statistics
we will estimate. The scaled fluctuations $z(t)$ of the number
infected around its expected value follow the stochastic differential
equation
\begin{equation}
\mathrm{d} z(t) = -az(t)\mathrm{d}t + b\mathrm{d}B(t),
\end{equation}
where where $B(t)$ is a standard Brownian motion and
\begin{align}
a &= -(\beta - 2 \beta I - \eta - \gamma), \\
b &= \sqrt{\beta I (1 - I) + \eta (1 - I) + \gamma I},
\end{align}
are functions of the SIS model parameters [@oregan2013, eq. 14]. These
parameters are $\beta$, the transmission rate; $\eta$, the rate of
infection from outside of the population; $\gamma$, the recovery
rate. $I$ is the expected fraction of infected individuals. $I$
satisfies $0 = \beta I (1 - I) + \eta (1 - I) - \gamma I$ when the
parameters are constant. If the parameters are changing at some small
rate $\epsilon \ll 1$, $I$ still remains close to that solution
[@kuehn2015]. By integrating over some time unit $\tau$, we find that
$z(t + \tau | z(t))$ is normally distributed with a mean of $z(t)
\mathrm{e}^{- a \tau}$ and a variance of $b^2 (1 - \mathrm{e}^{-2a
\tau}) / (2 a)$ [@ibe2013].

These mathematical results indicate that we simulate an approximate time
series of fluctuations with the following simple code.
```{r}
set.seed(123)
nobs <- 1000
ts <- numeric(nobs)
autocor <- numeric(nobs)
variance <- numeric(nobs)
ts[1] <- 0
beta <- 0.5
gamma <- 1
eta <- 1e-4
delta_beta <- (gamma - beta) / nobs
quadratic_formula <- function(a, b, c){
  (-b - sqrt(b^2 - 4 * a * c)) / (2 * a)
}
for (t in seq(1, nobs)){
  beta <- beta + delta_beta
  I <- quadratic_formula(-beta, beta - eta - gamma, eta)
  a <- -(beta - 2 * beta * I - eta - gamma)
  b <- sqrt(beta * I * (1 - I) + eta * (1 - I) + gamma * I)
  tau <- 1
  phi <- exp(-a * tau)
  var <- b ^ 2 / (2 * a)
  sigma <- (1 - exp(-a * 2 * tau)) * var
  if (t == 1) {
    ts[t] <- 0
  } else {
    ts[t] <- phi * ts[t - 1] + sigma * rnorm(1)
  }
  autocor[t] <- phi
  variance[t] <- var
}
```

It is clear that many statistic would change if evaluated along rolling windows of this time series.
```{r}
plot(ts, xlab="time", ylab="fluctuation, z", type="l")
```
In fact, we have calculated the expected autocorrelation and variance while doing the simulation and can plot them.
```{r}
par(mfrow=c(1,2))
plot(variance, xlab="time", ylab="Expected variance", type="l")
plot(autocor, xlab="time", ylab="Expected lag-1 autocorrelation", type="l")
par(mfrow=c(1,1))
```
In our simulation, $\beta$ was slowing increased and we stopped
shortly before the epidemic threshold for it was crossed. These
plots illustrate typical patterns in variance and
autocorrelation as a critical transition is being approached. The
\texttt{get\_dynamic\_acf} function of the spaero package is designed to
estimate these statistics from time series.

Two key parameters the user must determine for
\texttt{get\_dynamic\_acf} are the shape and size of the rolling
window. There is a rolling window for an estimate of the mean and for
an estimate of the autocovariance function. Arguments controlling
these windows are prefixed with the "center_" and "acf_"
respectively. We do not need to worry about estimating the mean for
our simulated data because we have simulated deviations around the
mean. In general, one might have to estimate the mean and subtract it
from the time series in order to properly estimate the autocovariance
function. That could be acheived by setting the "center_trend"
argument to something other than "assume_zero". Regarding the shapes
of windows, a rectangualar window function and a Gaussian-shaped
function are available by providing either "uniform" or "gaussian" to
the kernel arguments. The rectangular function may be preferred for
ease of interpretation while the Gaussian function may be preferred
for obtaining a smoother series of estimates. The width of the window
is controlled by the bandwidth arguments. For a window centered on a
particular index, the absolute difference between that index and all
other indices in the time series is divided by the bandwidth to
determine a distance to all other observations. This distance is then
plugged into a kernel function corresponding to the window type. For
the Guassian window, the kernel function is a Gaussian probability
density function with a standard deviation of one. For the rectangular
window, the kernel function equals one if the distance is less than
one and zero otherwise. The output of the kernel function is a weight
for each observation. These weights are used in the estimators
described next.

This paragraph explains how the covariance is estimated.

This paragraph explains shows how the estimates compare to theoretical expections.

## References
